{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "0e2e8e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "06899936",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imports complete (lightweight + sentiment ready)\n"
     ]
    }
   ],
   "source": [
    "# --- Cell 1: imports & setup ---\n",
    "import streamlit as st\n",
    "import re, string\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import joblib\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Lightweight sentiment (VADER via NLTK)\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "import nltk\n",
    "nltk.download('vader_lexicon', quiet=True)\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "pd.set_option('display.max_colwidth', 200)\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "print(\"Imports complete (lightweight + sentiment ready)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "1db4774c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello this is great\n"
     ]
    }
   ],
   "source": [
    "# --- Cell 2: text cleaning ---\n",
    "def clean_text(text):\n",
    "    \"\"\"Lowercase, remove punctuation, collapse whitespace.\"\"\"\n",
    "    if pd.isna(text):\n",
    "        return \"\"\n",
    "    s = str(text).lower()\n",
    "    s = re.sub(f\"[{re.escape(string.punctuation)}]\", \" \", s)\n",
    "    s = re.sub(r\"\\s+\", \" \", s).strip()\n",
    "    return s\n",
    "\n",
    "# quick sanity check\n",
    "print(clean_text(\"Hello!! This is GREAT :-)  \\n\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "9b745d5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intents: 252, FAQ: 70, Menu: 255\n"
     ]
    }
   ],
   "source": [
    "# --- Cell 3: Load datasets ---\n",
    "DATA_DIR = Path(\"data\")\n",
    "DATA_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "# Intents dataset (must include: text, intent, emotion)\n",
    "df_intents = pd.read_csv(DATA_DIR / \"intents.txt\", sep=\"\\t\")\n",
    "for c in [\"text\", \"intent\", \"emotion\"]:\n",
    "    if c not in df_intents.columns:\n",
    "        raise ValueError(\"intents.txt must include columns: text, intent, emotion\")\n",
    "df_intents[\"text\"] = df_intents[\"text\"].astype(str)\n",
    "df_intents[\"intent\"] = df_intents[\"intent\"].astype(str)\n",
    "df_intents[\"emotion\"] = df_intents[\"emotion\"].astype(str)\n",
    "\n",
    "# FAQ dataset\n",
    "df_faq = pd.read_csv(DATA_DIR / \"restaurant_faq.csv\")\n",
    "df_faq.columns = [c.lower() for c in df_faq.columns]\n",
    "for c in [\"question\", \"answer\"]:\n",
    "    if c not in df_faq.columns:\n",
    "        raise ValueError(\"restaurant_faq.csv must include columns: Question, Answer (or lowercase)\")\n",
    "\n",
    "# Menu dataset\n",
    "df_menu = pd.read_csv(DATA_DIR / \"menu.csv\")\n",
    "expected_cols = ['name', 'ingredients', 'diet', 'cook_time', 'flavor_profile', 'course']\n",
    "for col in expected_cols:\n",
    "    if col not in df_menu.columns:\n",
    "        raise ValueError(f\"menu.csv missing column: {col}\")\n",
    "\n",
    "print(f\"Intents: {len(df_intents)}, FAQ: {len(df_faq)}, Menu: {len(df_menu)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "c593371c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intent Accuracy: 0.7843\n",
      "Emotion Accuracy: 0.8627\n"
     ]
    }
   ],
   "source": [
    "# --- Cell 4: Preprocess & Train (different process: CountVectorizer + MultinomialNB) ---\n",
    "texts = df_intents['text'].apply(clean_text).values\n",
    "intent_labels = df_intents['intent'].values\n",
    "emotion_labels = df_intents['emotion'].values\n",
    "\n",
    "X_train, X_test, y_intent_train, y_intent_test, y_emotion_train, y_emotion_test = train_test_split(\n",
    "    texts, intent_labels, emotion_labels, test_size=0.2, random_state=42, stratify=intent_labels\n",
    ")\n",
    "\n",
    "# Use CountVectorizer (different from TF-IDF + Logistic Regression used by your teammate)\n",
    "vectorizer = CountVectorizer(ngram_range=(1,2), stop_words='english', max_features=5000)\n",
    "X_train_vec = vectorizer.fit_transform(X_train)\n",
    "X_test_vec  = vectorizer.transform(X_test)\n",
    "\n",
    "# Multinomial Naive Bayes (different model choice)\n",
    "clf_intent  = MultinomialNB().fit(X_train_vec, y_intent_train)\n",
    "clf_emotion = MultinomialNB().fit(X_train_vec, y_emotion_train)\n",
    "\n",
    "print(\"Intent Accuracy:\",  round(accuracy_score(y_intent_test,  clf_intent.predict(X_test_vec)),  4))\n",
    "print(\"Emotion Accuracy:\", round(accuracy_score(y_emotion_test, clf_emotion.predict(X_test_vec)), 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "fac7a42d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models and vectorizer saved.\n"
     ]
    }
   ],
   "source": [
    "# --- Cell 5: Save models ---\n",
    "MODEL_PATH = Path(\"models\")\n",
    "MODEL_PATH.mkdir(exist_ok=True)\n",
    "\n",
    "joblib.dump(clf_intent,  MODEL_PATH / \"intent_classifier_nb.joblib\")\n",
    "joblib.dump(clf_emotion, MODEL_PATH / \"emotion_classifier_nb.joblib\")\n",
    "joblib.dump(vectorizer,   MODEL_PATH / \"count_vectorizer.joblib\")\n",
    "print(\"Models and vectorizer saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "778a70c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Cell 6: FAQ retriever (TF-IDF + cosine similarity + threshold) ---\n",
    "df_faq['clean_question'] = df_faq['question'].astype(str).apply(clean_text)\n",
    "faq_vectorizer = TfidfVectorizer(ngram_range=(1,2), stop_words='english')\n",
    "faq_matrix = faq_vectorizer.fit_transform(df_faq['clean_question'])\n",
    "\n",
    "def search_faq(user_text, top_k=3, threshold=0.35):\n",
    "    \"\"\"Return top-k FAQ matches above similarity threshold.\"\"\"\n",
    "    user_clean = clean_text(user_text)\n",
    "    user_vec = faq_vectorizer.transform([user_clean])\n",
    "    sims = cosine_similarity(user_vec, faq_matrix)[0]\n",
    "    idx_sorted = sims.argsort()[::-1]\n",
    "\n",
    "    results = []\n",
    "    for i in idx_sorted[:top_k]:\n",
    "        if sims[i] >= threshold:\n",
    "            results.append({\n",
    "                \"question\": df_faq.iloc[i][\"question\"],\n",
    "                \"answer\":   df_faq.iloc[i][\"answer\"],\n",
    "                \"score\":    float(sims[i])\n",
    "            })\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "b97a1f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Cell 7: menu search (robust + keyword-aware) ---\n",
    "# Normalize important text columns\n",
    "for col in ['name', 'ingredients', 'diet', 'flavor_profile', 'course']:\n",
    "    if col in df_menu.columns:\n",
    "        df_menu[col] = df_menu[col].astype(str).apply(clean_text)\n",
    "    else:\n",
    "        df_menu[col] = \"\"  # guard just in case\n",
    "\n",
    "# Keyword pools\n",
    "DIET_KEYWORDS = {\n",
    "    \"vegan\": [\"vegan\"],\n",
    "    \"vegetarian\": [\"vegetarian\", \"veg\"],\n",
    "    \"non_vegetarian\": [\"non vegetarian\", \"non-vegetarian\", \"chicken\", \"meat\", \"fish\", \"egg\"],\n",
    "    \"gluten_free\": [\"gluten free\", \"gluten-free\", \"no gluten\"]\n",
    "}\n",
    "FLAVOR_KEYWORDS = [\"spicy\", \"sweet\", \"savory\", \"sour\", \"bitter\", \"mild\", \"hot\"]\n",
    "\n",
    "def _contains_any(text: str, words) -> bool:\n",
    "    return any(w in text for w in words)\n",
    "\n",
    "def search_menu(user_text: str, top_k: int = 5):\n",
    "    \"\"\"Heuristic menu search: diet → flavor → ingredients/name tokens.\"\"\"\n",
    "    t = clean_text(user_text)\n",
    "\n",
    "    # 1) Diet filter\n",
    "    if _contains_any(t, DIET_KEYWORDS[\"vegan\"]):\n",
    "        hits = df_menu[df_menu[\"diet\"].str.contains(\"vegan\")]\n",
    "        if not hits.empty:\n",
    "            return hits.head(top_k).to_dict(\"records\")\n",
    "\n",
    "    if _contains_any(t, DIET_KEYWORDS[\"vegetarian\"]) and \"non vegetarian\" not in t:\n",
    "        hits = df_menu[df_menu[\"diet\"].str.contains(\"vegetarian\")]\n",
    "        if not hits.empty:\n",
    "            return hits.head(top_k).to_dict(\"records\")\n",
    "\n",
    "    if _contains_any(t, DIET_KEYWORDS[\"non_vegetarian\"]):\n",
    "        hits = df_menu[df_menu[\"diet\"].str.contains(\"non vegetarian\")]\n",
    "        if not hits.empty:\n",
    "            return hits.head(top_k).to_dict(\"records\")\n",
    "\n",
    "    # 2) Flavor match\n",
    "    for flavor in FLAVOR_KEYWORDS:\n",
    "        if flavor in t:\n",
    "            hits = df_menu[df_menu[\"flavor_profile\"].str.contains(flavor)]\n",
    "            if not hits.empty:\n",
    "                return hits.head(top_k).to_dict(\"records\")\n",
    "\n",
    "    # 3) Token overlap on ingredients / name\n",
    "    tokens = set(t.split())\n",
    "    scored = []\n",
    "    for _, row in df_menu.iterrows():\n",
    "        text_blob = f\"{row['name']} {row['ingredients']}\"\n",
    "        menu_tokens = set(text_blob.split())\n",
    "        overlap = len(tokens & menu_tokens)\n",
    "        if overlap > 0:\n",
    "            scored.append((overlap, row.to_dict()))\n",
    "\n",
    "    if scored:\n",
    "        scored.sort(key=lambda x: x[0], reverse=True)\n",
    "        return [r for _, r in scored[:top_k]]\n",
    "\n",
    "    # 4) Fallback: name substring\n",
    "    if len(t) >= 3:\n",
    "        hits = df_menu[df_menu[\"name\"].str.contains(t)]\n",
    "        if not hits.empty:\n",
    "            return hits.head(top_k).to_dict(\"records\")\n",
    "\n",
    "    return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "eaf714a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Cell 8: prediction & sentiment helpers (with \"thanks\" fast-path) ---\n",
    "def predict_intent(user_text: str):\n",
    "    vec = vectorizer.transform([clean_text(user_text)])\n",
    "    probs = clf_intent.predict_proba(vec)[0]\n",
    "    idx = int(np.argmax(probs))\n",
    "    return clf_intent.classes_[idx], float(probs[idx])\n",
    "\n",
    "def predict_emotion(user_text: str):\n",
    "    vec = vectorizer.transform([clean_text(user_text)])\n",
    "    probs = clf_emotion.predict_proba(vec)[0]\n",
    "    idx = int(np.argmax(probs))\n",
    "    return clf_emotion.classes_[idx], float(probs[idx])\n",
    "\n",
    "def get_sentiment(user_text: str):\n",
    "    s = sia.polarity_scores(user_text)\n",
    "    comp = s[\"compound\"]\n",
    "    if comp >= 0.05:\n",
    "        label = \"positive\"\n",
    "    elif comp <= -0.05:\n",
    "        label = \"negative\"\n",
    "    else:\n",
    "        label = \"neutral\"\n",
    "    return label, comp\n",
    "\n",
    "def format_menu_results(records):\n",
    "    if not records:\n",
    "        return \"I couldn't find matching menu items.\"\n",
    "    lines = []\n",
    "    for r in records:\n",
    "        name = r.get(\"name\", \"Unknown\").title()\n",
    "        diet = r.get(\"diet\", \"\").strip()\n",
    "        flavor = r.get(\"flavor_profile\", \"\").strip()\n",
    "        ings = r.get(\"ingredients\", \"\").strip()\n",
    "        parts = []\n",
    "        if diet: parts.append(diet)\n",
    "        if flavor: parts.append(flavor)\n",
    "        meta = f\" ({', '.join(parts)})\" if parts else \"\"\n",
    "        lines.append(f\"- {name}{meta} — Ingredients: {ings}\")\n",
    "    return \"Here are some suggestions:\\n\" + \"\\n\".join(lines)\n",
    "\n",
    "THANKS_PATTERNS = (\n",
    "    \"thanks\", \"thank you\", \"appreciate\", \"thx\", \"ty\", \"many thanks\"\n",
    ")\n",
    "GREET_PATTERNS = (\n",
    "    \"hi\", \"hello\", \"hey\", \"good morning\", \"good afternoon\", \"good evening\"\n",
    ")\n",
    "\n",
    "def is_thanks(text: str) -> bool:\n",
    "    t = clean_text(text)\n",
    "    return any(p in t for p in THANKS_PATTERNS)\n",
    "\n",
    "def is_greeting(text: str) -> bool:\n",
    "    t = clean_text(text)\n",
    "    return any(t.startswith(p) or f\" {p} \" in f\" {t} \" for p in GREET_PATTERNS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "379695e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Cell 9: get_bot_response (routing + FAQ + menu + sentiment-aware) ---\n",
    "def get_bot_response(user_text: str, confidence_threshold: float = 0.35) -> str:\n",
    "    # Fast-path: explicit thanks\n",
    "    if is_thanks(user_text):\n",
    "        return random.choice([\n",
    "            \"You're welcome! 😊\",\n",
    "            \"Anytime! Happy to help.\",\n",
    "            \"You're most welcome.\"\n",
    "        ])\n",
    "\n",
    "    # Sentiment & soft empathy\n",
    "    sent_label, sent_score = get_sentiment(user_text)\n",
    "    empathy = \"\"\n",
    "    if sent_label == \"negative\":\n",
    "        empathy = \"I'm really sorry you're feeling this way. \"\n",
    "    elif sent_label == \"positive\":\n",
    "        empathy = \"Glad to hear that! \"\n",
    "\n",
    "    # Model predictions\n",
    "    intent_label, intent_prob = predict_intent(user_text)\n",
    "\n",
    "    # Low-confidence → try FAQ, then Menu, then fallback\n",
    "    if intent_prob < confidence_threshold:\n",
    "        hits = search_faq(user_text, top_k=1, threshold=0.3)\n",
    "        if hits:\n",
    "            return empathy + hits[0][\"answer\"]\n",
    "        menu_hits = search_menu(user_text, top_k=5)\n",
    "        if menu_hits:\n",
    "            return empathy + format_menu_results(menu_hits)\n",
    "        return empathy + \"Sorry, I didn't quite get that. You can ask about our **menu** or any **FAQ** like hours, parking, or reservations.\"\n",
    "\n",
    "    # High-confidence routing\n",
    "    if intent_label.startswith(\"faq\"):\n",
    "        hits = search_faq(user_text, top_k=1, threshold=0.3)\n",
    "        if hits:\n",
    "            return empathy + hits[0][\"answer\"]\n",
    "        return empathy + \"I recognized this as an FAQ, but I couldn't find a close match. Could you rephrase it?\"\n",
    "\n",
    "    if intent_label.startswith(\"menu\"):\n",
    "        menu_hits = search_menu(user_text, top_k=5)\n",
    "        if menu_hits:\n",
    "            return empathy + format_menu_results(menu_hits)\n",
    "        return empathy + \"I understood you're asking about the menu, but I couldn't find matching items.\"\n",
    "\n",
    "    if intent_label == \"greeting\":\n",
    "        return random.choice([\n",
    "            \"Hi there 👋 How can I help you today?\",\n",
    "            \"Hello! How can I assist you—menu suggestions or FAQs?\",\n",
    "            \"Hey! What would you like to know?\"\n",
    "        ])\n",
    "\n",
    "    if intent_label == \"farewell\":\n",
    "        return random.choice([\n",
    "            \"Goodbye — have a wonderful day!\",\n",
    "            \"See you next time!\",\n",
    "            \"Take care! 👋\"\n",
    "        ])\n",
    "\n",
    "    # For \"other\" or anything else, reflect emotion if classifier captured it\n",
    "    emotion_label, _ = predict_emotion(user_text)\n",
    "    emotion_word = emotion_label.replace(\"none\", \"neutral\").replace(\"_\", \" \")\n",
    "    return empathy + f\"I got you. If you need help with our **menu** or **reservations**, just ask! (Detected emotion: {emotion_word})\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "a6d3e55e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-19 05:46:33.028 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-08-19 05:46:33.029 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-08-19 05:46:33.029 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-08-19 05:46:33.029 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-08-19 05:46:33.029 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-08-19 05:46:33.030 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-08-19 05:46:33.030 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-08-19 05:46:33.030 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-08-19 05:46:33.031 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-08-19 05:46:33.031 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-08-19 05:46:33.031 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-08-19 05:46:33.032 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-08-19 05:46:33.032 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-08-19 05:46:33.032 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-08-19 05:46:33.033 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-08-19 05:46:33.033 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
     ]
    }
   ],
   "source": [
    "# --- Cell 10: Streamlit chat UI (with first AI message) ---\n",
    "st.set_page_config(page_title=\"Restaurant Chatbot\", page_icon=\"🍽️\", layout=\"centered\")\n",
    "st.title(\"🍽️ Restaurant Chatbot (Lightweight + Sentiment)\")\n",
    "\n",
    "# Keep a simple chat history\n",
    "if \"chat\" not in st.session_state:\n",
    "    st.session_state.chat = []\n",
    "    # First AI message (AI-style greeting)\n",
    "    st.session_state.chat.append((\"bot\", \"Hi there 👋 How can I help you today?\"))\n",
    "\n",
    "# Render chat so far\n",
    "for role, msg in st.session_state.chat:\n",
    "    if role == \"user\":\n",
    "        st.markdown(f\"**You:** {msg}\")\n",
    "    else:\n",
    "        st.markdown(f\"**Bot:** {msg}\")\n",
    "\n",
    "# Input box\n",
    "user_input = st.text_input(\"Type your message and press Enter:\", \"\", key=\"user_input_box\")\n",
    "\n",
    "if user_input:\n",
    "    st.session_state.chat.append((\"user\", user_input))\n",
    "    bot_reply = get_bot_response(user_input)\n",
    "    st.session_state.chat.append((\"bot\", bot_reply))\n",
    "    st.experimental_rerun()  # refresh to show the new messages immediately\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "65cf11f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Quick Tests ---\n",
      "User: Hi!\n",
      "Bot : I got you. If you need help with our **menu** or **reservations**, just ask! (Detected emotion: neutral)\n",
      "----------------------------------------\n",
      "User: Thanks for the help\n",
      "Bot : You're most welcome.\n",
      "----------------------------------------\n",
      "User: Do you have outdoor seating?\n",
      "Bot : Yes, we have a lovely outdoor seating area.\n",
      "----------------------------------------\n",
      "User: What time do you open?\n",
      "Bot : Yes, we are open on most public holidays unless stated otherwise.\n",
      "----------------------------------------\n",
      "User: I want something spicy\n",
      "Bot : Glad to hear that! I got you. If you need help with our **menu** or **reservations**, just ask! (Detected emotion: neutral)\n",
      "----------------------------------------\n",
      "User: I'm really unhappy with my order\n",
      "Bot : I'm really sorry you're feeling this way. I got you. If you need help with our **menu** or **reservations**, just ask! (Detected emotion: negative)\n",
      "----------------------------------------\n",
      "User: Goodbye!\n",
      "Bot : Sorry, I didn't quite get that. You can ask about our **menu** or any **FAQ** like hours, parking, or reservations.\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# --- Cell 11: Quick local tests (stdout) ---\n",
    "test_inputs = [\n",
    "    \"Hi!\",\n",
    "    \"Thanks for the help\",\n",
    "    \"Do you have outdoor seating?\",\n",
    "    \"What time do you open?\",\n",
    "    \"I want something spicy\",\n",
    "    \"I'm really unhappy with my order\",\n",
    "    \"Goodbye!\"\n",
    "]\n",
    "print(\"\\n--- Quick Tests ---\")\n",
    "for t in test_inputs:\n",
    "    print(f\"User: {t}\")\n",
    "    print(f\"Bot : {get_bot_response(t)}\")\n",
    "    print(\"-\" * 40)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
